# Daily Batches CSV Consolidation

This document explains how to use the daily batch consolidation feature to merge all individual daily CSV files into a single comprehensive dataset.

## ğŸ“Š Overview

The consolidation script merges all CSV files from the `output/daily-batches/` directory into a single file called `consolidated_daily_batches.csv` in the `output/` directory.

## ğŸš€ Usage

### Option 1: Using npm script (Recommended)
```bash
npm run consolidate
```

### Option 2: Direct execution
```bash
node src/consolidate-daily-batches.js
```

## ğŸ“ Input and Output

### Input Files
- **Location**: `output/daily-batches/`
- **Format**: `Zubale_daily_YYYY-MM-DD.csv`
- **Content**: Individual daily commit data with AI analysis

### Output File
- **Location**: `output/consolidated_daily_batches.csv`
- **Content**: All daily data merged chronologically
- **Size**: Typically 60KB+ depending on data volume

## ğŸ“‹ Data Structure

The consolidated CSV maintains the same structure as individual daily files:

| Column | Description |
|--------|-------------|
| Date | Commit date (YYYY-MM-DD) |
| Team | Team name |
| TeamSlug | Team identifier |
| TeamMembers | Number of team members |
| Repository | Repository name |
| Contributor | Developer username |
| CommitSHA | Full commit SHA hash |
| CommitMessage | Commit message text |
| CodeLines | Lines of code in commit |
| AILines | AI-assisted lines of code |
| AIPercentage | Percentage of AI assistance |
| Additions | Lines added |
| Deletions | Lines deleted |
| TotalChanges | Total lines changed |

## ğŸ“Š Features

### Data Processing
- âœ… **Chronological Sorting**: Data sorted by date for time-series analysis
- âœ… **Data Cleaning**: Removes quotes and validates data types
- âœ… **Duplicate Handling**: Preserves all commit records individually
- âœ… **Error Handling**: Skips invalid rows with warnings

### Statistics
The script provides comprehensive statistics including:
- ğŸ“… Date range coverage
- ğŸ¢ Number of unique teams
- ğŸ‘¥ Number of unique contributors
- ğŸ“¦ Number of unique repositories
- ğŸ“ Total commit count
- ğŸ’» Total lines of code
- ğŸ¤– Total AI-assisted lines
- ğŸ“Š Average AI assistance percentage

## ğŸ”§ Requirements

### Dependencies
The script automatically installs required dependencies:
- `csv-parser`: For reading CSV files
- `csv-writer`: For writing the consolidated CSV

### Node.js Version
- Node.js 12+ required
- Tested with Node.js 20+

## ğŸ“ˆ Example Output

```
ğŸ”„ Starting daily batch consolidation...
ğŸ“ Reading from: /path/to/output/daily-batches
ğŸ“ Output file: /path/to/output/consolidated_daily_batches.csv
ğŸ“Š Found 20 CSV files to consolidate
ğŸ“– Processing: Zubale_daily_2025-05-15.csv
   âœ“ Added 34 records from Zubale_daily_2025-05-15.csv
...
âœ… Consolidation complete!
ğŸ“Š Total records: 326

ğŸ“Š CONSOLIDATION SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“… Date Range: 2025-05-15 to 2025-06-10
ğŸ¢ Teams: 7
ğŸ‘¥ Contributors: 22
ğŸ“¦ Repositories: 19
ğŸ“ Total Commits: 326
ğŸ’» Total Code Lines: 61,247
ğŸ¤– Total AI Lines: 2,804
ğŸ“Š Average AI Assistance: 4.6%
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ” Use Cases

### Dashboard Integration
The consolidated file can be used with the web dashboard for:
- Complete historical analysis
- Long-term trend visualization
- Cross-team comparisons
- AI adoption tracking

### Data Analysis
Perfect for:
- ğŸ“Š Business intelligence tools
- ğŸ“ˆ Custom analytics scripts
- ğŸ“‹ Reporting and presentations
- ğŸ”„ Data backup and archival

### Performance Benefits
- **Faster Loading**: Single file vs. multiple files
- **Simplified Queries**: No need to join multiple datasets
- **Complete Dataset**: All historical data in one place

## âš ï¸ Important Notes

1. **File Size**: The consolidated file grows with each daily batch
2. **Regeneration**: Run consolidation after new daily batches are created
3. **Backup**: Consider backing up individual daily files before consolidation
4. **Memory Usage**: Large datasets may require increased Node.js memory limits

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Permission Errors**
```bash
# Ensure output directory is writable
chmod 755 output/
```

**Memory Issues (Large Datasets)**
```bash
# Increase Node.js memory limit
node --max-old-space-size=4096 src/consolidate-daily-batches.js
```

**Missing Dependencies**
```bash
# Install dependencies manually
npm install csv-parser csv-writer
```

## ğŸ“ Integration with Package.json

The consolidation script is integrated into the project's npm scripts:

```json
{
  "scripts": {
    "consolidate": "node src/consolidate-daily-batches.js"
  },
  "dependencies": {
    "csv-parser": "^3.0.0",
    "csv-writer": "^1.6.0"
  }
}
```
